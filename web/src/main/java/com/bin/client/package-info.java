package com.bin.client;
/**
 *  轻重隔离
 *      核心->
 *         业务按照 Level 进行资源池划分(L0/L1/L2)
 *      快慢->
 *         按照各种纬度隔离：部门、业务、logid、重要性(S/A/B/C)(业务日志也属于某个 logid，日志等级就可以作为隔离通道。)
 *      热点->
 *         使用localcache,
 *      线程隔离
 *
 *   超时控制->超时决定着服务线程耗尽
 *
 *   过载保护->自适应的限流算法
 *        服务器临近过载时，主动抛弃一定量的负载，目标是自保
 *        CPU、内存作为信号量进行节流;队列管理: 队列长度、LIFO;可控延迟算法: CoDel
 *        规则
 *        CPU: 使用一个独立的线程采样，每隔 250ms 触发一次。在计算均值时，使用了简单滑动平均去除峰值的影响
 *        Inflight: 当前服务中正在进行的请求的数量
 *        Pass&RT: 最近5s，pass 为每100ms采样窗口内成功请求的数量，rt 为单个采样窗口中平均响应时间
 *        做法
 *        使用 CPU 的滑动均值(CPU > 800)作为启发阈值，一旦触发进入到过载保护阶段，算法为：(pass* rt) < inflight
 *        限流效果生效后，CPU 会在临界值(800)附近抖动，如果不使用冷却时间
 *        那么一个短时间的 CPU 下降就可能导致大量请求被放行，严重时会打满 CPU
 *        在冷却时间后，重新判断阈值(CPU > 800 )，是否持续进入过载保护
 *
 *   限流->BBR限流
 *       给每个用户设置限制;
 *       全局过载发生时候，针对某些“异常”进行控制;(一定程度的“超卖”配额)
 *       按照优先级丢弃;(拒绝请求也需要成本)
 *       请求类型重要性(criticality):
 *              最重要 CRITICAL_PLUS，为最终的要求预留的类型，拒绝这些请求会造成非常严重的用户可见的问题。
 *              重要 CRITICAL，生产任务发出的默认请求类型。拒绝这些请求也会造成用户可见的问题。但是可能没那么严重
 *              可丢弃的 SHEDDABLE_PLUS 这些流量可以容忍某种程度的不可用性。这是批量任务发出的请求的默认值。这些请求通常可以过几分钟、几小时后重试
 *              可丢弃的 SHEDDABLE 这些流量可能会经常遇到部分不可用情况，偶尔会完全不可用
 *              全局配额不足时，优先拒绝低优先级的
 *              全局配额，可以按照重要性分别设置
 *              过载保护时，低优先级的请求先被拒绝
 *
 *    熔断->基于熔断的 gutter kafka
 *        failover(失效转移) 的思路需要翻倍的机器资源,平常不接受流量时，资源浪费。高负载情况下接管流量又不一定完整能接住
 *        利用熔断的思路，是把抛弃的流量转移到 gutter kafka集群，如果 gutter kafka也接受不住的流量，重新回抛到主集群，最大力度来接受。
 *
 *    降级->本质:提供有损服务、非核心模块降级;
 *
 *    负载均衡-><The power of two choices in randomized load balancing>文章; Latency-Aware算法
 *        the choice-of-2 算法，随机选取的两个节点进行打分，选择更优的节点;
 *        选择 backend：CPU，client：health、inflight、latency 作为指标，使用一个简单的线性方程进行打分
 *        对新启动的节点使用常量惩罚值(penalty)，以及使用探针方式最小化放量，进行预热
 *        打分比较低的节点，避免进入“永久黑名单”而无法恢复，使用统计衰减的方式，让节点指标逐渐恢复到初始状态(即默认值)
 *        指标计算结合 moving average，使用时间衰减，计算vt = v(t-1) * β + at * (1-β) ，β为若干次幂的倒数即: Math.Exp((-span) / 600ms)
 *
 *
 *
 *
 *
 *
 *
 *
 */